{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume tar.gz file to be extracted at project directory.\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
    "train_batch_2 = unpickle('cifar-10-batches-py/data_batch_2')\n",
    "train_batch_3 = unpickle('cifar-10-batches-py/data_batch_3')\n",
    "train_batch_4 = unpickle('cifar-10-batches-py/data_batch_4')\n",
    "train_batch_5 = unpickle('cifar-10-batches-py/data_batch_5')\n",
    "test_batch = unpickle('cifar-10-batches-py/test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_image(data):\n",
    "    data = np.reshape(data, (3,32,32))\n",
    "    data = np.moveaxis(data, 0, -1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_classes(batch, label):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    true_count = 0\n",
    "    false_count = 0\n",
    "\n",
    "    labels = np.array([int(i == label) for i in batch[b'labels']])\n",
    "\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    n = min(counts)\n",
    "\n",
    "    for i in range(len(batch[b'data'])):\n",
    "        if batch[b'labels'][i] == label:\n",
    "            if true_count < n:\n",
    "                x.append(reshape_image(batch[b'data'][i]))\n",
    "                y.append(1)\n",
    "                true_count += 1\n",
    "        else:\n",
    "            if false_count < n:\n",
    "                x.append(reshape_image(batch[b'data'][i]))\n",
    "                y.append(0)\n",
    "                false_count += 1\n",
    "\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1, train_y1 = filter_classes(train_batch_1, 0)\n",
    "train_x2, train_y2 = filter_classes(train_batch_2, 0)\n",
    "train_x3, train_y3 = filter_classes(train_batch_3, 0)\n",
    "train_x4, train_y4 = filter_classes(train_batch_4, 0)\n",
    "train_x5, train_y5 = filter_classes(train_batch_5, 0)\n",
    "\n",
    "train_x = np.concatenate((train_x1, train_x2, train_x3, train_x4, train_x5))\n",
    "train_y = np.concatenate((train_y1, train_y2, train_y3, train_y4, train_y5))\n",
    "test_x, test_y = filter_classes(test_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, layers, Sequential, optimizers, losses, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS_1 = hp.HParam('num_units_1', hp.Discrete([28, 32]))\n",
    "HP_NUM_UNITS_2 = hp.HParam('num_units_2', hp.Discrete([48, 52]))\n",
    "HP_NUM_UNITS_3 = hp.HParam('num_units_3', hp.Discrete([68, 72]))\n",
    "HP_NUM_UNITS_4 = hp.HParam('num_units_4', hp.Discrete([100, 104]))\n",
    "\n",
    "HP_DROPOUT_3 = hp.HParam('dropout_3', hp.Discrete([0.2]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[\n",
    "            HP_NUM_UNITS_1,\n",
    "            HP_NUM_UNITS_2,\n",
    "            HP_NUM_UNITS_3,\n",
    "            HP_NUM_UNITS_4,\n",
    "            HP_DROPOUT_3,\n",
    "            ],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    data_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\",\n",
    "        input_shape=(32,32,3)),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    model = Sequential(name=\"Image_Recognition_Model\")\n",
    "    model.add(Input(shape=(32,32,3,))) # Input layer.\n",
    "\n",
    "    model.add(data_augmentation)\n",
    "    model.add(layers.Rescaling(scale=1./255, name=\"Normaliser\")) # Example pre-processing layer.\n",
    "\n",
    "    model.add(layers.Conv2D(hparams[HP_NUM_UNITS_1], 3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(hparams[HP_NUM_UNITS_2], 3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(hparams[HP_NUM_UNITS_3], 3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(hparams[HP_DROPOUT_3]))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(hparams[HP_NUM_UNITS_4], activation='relu'))\n",
    "    model.add(layers.Dense(2))\n",
    "    \n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam', #optimizers.SGD(learning_rate=0.1),\n",
    "        loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        epochs=5,\n",
    "        # callbacks=[\n",
    "        #     callbacks.TensorBoard('output\\\\logs'),\n",
    "        #     hp.KerasCallback('output\\\\logs', hparams),\n",
    "        # ]\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    _, accuracy = model.evaluate(test_x, test_y)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units_1': 28, 'num_units_2': 48, 'num_units_3': 68, 'num_units_4': 100, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.3862 - accuracy: 0.8335\n",
      "--- Starting trial: run-1\n",
      "{'num_units_1': 28, 'num_units_2': 48, 'num_units_3': 68, 'num_units_4': 104, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 0.3473 - accuracy: 0.8450\n",
      "--- Starting trial: run-2\n",
      "{'num_units_1': 28, 'num_units_2': 48, 'num_units_3': 72, 'num_units_4': 100, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.3734 - accuracy: 0.8460\n",
      "--- Starting trial: run-3\n",
      "{'num_units_1': 28, 'num_units_2': 48, 'num_units_3': 72, 'num_units_4': 104, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.4185 - accuracy: 0.8055\n",
      "--- Starting trial: run-4\n",
      "{'num_units_1': 28, 'num_units_2': 52, 'num_units_3': 68, 'num_units_4': 100, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.3687 - accuracy: 0.8325\n",
      "--- Starting trial: run-5\n",
      "{'num_units_1': 28, 'num_units_2': 52, 'num_units_3': 68, 'num_units_4': 104, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.3630 - accuracy: 0.8445\n",
      "--- Starting trial: run-6\n",
      "{'num_units_1': 28, 'num_units_2': 52, 'num_units_3': 72, 'num_units_4': 100, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.4131 - accuracy: 0.8030\n",
      "--- Starting trial: run-7\n",
      "{'num_units_1': 28, 'num_units_2': 52, 'num_units_3': 72, 'num_units_4': 104, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3393 - accuracy: 0.8515\n",
      "--- Starting trial: run-8\n",
      "{'num_units_1': 32, 'num_units_2': 48, 'num_units_3': 68, 'num_units_4': 100, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3519 - accuracy: 0.8485\n",
      "--- Starting trial: run-9\n",
      "{'num_units_1': 32, 'num_units_2': 48, 'num_units_3': 68, 'num_units_4': 104, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3564 - accuracy: 0.8360\n",
      "--- Starting trial: run-10\n",
      "{'num_units_1': 32, 'num_units_2': 48, 'num_units_3': 72, 'num_units_4': 100, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 2s 8ms/step - loss: 0.3974 - accuracy: 0.8210\n",
      "--- Starting trial: run-11\n",
      "{'num_units_1': 32, 'num_units_2': 48, 'num_units_3': 72, 'num_units_4': 104, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.3358 - accuracy: 0.8510\n",
      "--- Starting trial: run-12\n",
      "{'num_units_1': 32, 'num_units_2': 52, 'num_units_3': 68, 'num_units_4': 100, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.3597 - accuracy: 0.8490\n",
      "--- Starting trial: run-13\n",
      "{'num_units_1': 32, 'num_units_2': 52, 'num_units_3': 68, 'num_units_4': 104, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.3529 - accuracy: 0.8415\n",
      "--- Starting trial: run-14\n",
      "{'num_units_1': 32, 'num_units_2': 52, 'num_units_3': 72, 'num_units_4': 100, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.3478 - accuracy: 0.8545\n",
      "--- Starting trial: run-15\n",
      "{'num_units_1': 32, 'num_units_2': 52, 'num_units_3': 72, 'num_units_4': 104, 'dropout_3': 0.2}\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.3555 - accuracy: 0.8485\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units_1 in HP_NUM_UNITS_1.domain.values:\n",
    "    for num_units_2 in HP_NUM_UNITS_2.domain.values:\n",
    "        for num_units_3 in HP_NUM_UNITS_3.domain.values:\n",
    "            for num_units_4 in HP_NUM_UNITS_4.domain.values:\n",
    "                for dropout_3 in HP_DROPOUT_3.domain.values:\n",
    "                    hparams = {\n",
    "                        HP_NUM_UNITS_1: num_units_1,\n",
    "                        HP_NUM_UNITS_2: num_units_2,\n",
    "                        HP_NUM_UNITS_3: num_units_3,\n",
    "                        HP_NUM_UNITS_4: num_units_4,\n",
    "                        HP_DROPOUT_3: dropout_3,\n",
    "                    }\n",
    "                    run_name = \"run-%d\" % session_num\n",
    "                    print('--- Starting trial: %s' % run_name)\n",
    "                    print({h.name: hparams[h] for h in hparams})\n",
    "                    run('logs\\\\hparam_tuning\\\\' + run_name, hparams)\n",
    "                    session_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 28024), started 17:49:03 ago. (Use '!kill 28024' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-78a1218592b05453\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-78a1218592b05453\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adffc049c0057b7f9c7b7f1d164dfcad4547c7e894a42e2b6795b142f0f78ed4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
